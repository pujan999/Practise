{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Student Name:Pujan Sharma Student ID: 1928447"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pujan\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "C:\\Users\\pujan\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:451: DeprecationWarning: The 'categorical_features' keyword is deprecated in version 0.20 and will be removed in 0.22. You can use the ColumnTransformer instead.\n",
      "  \"use the ColumnTransformer instead.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# Multiple Linear Regression\n",
    "\n",
    "# Importing the libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Importing the dataset\n",
    "dataset = pd.read_csv('50_Startups.csv')\n",
    "X = dataset.iloc[:, :-1].values\n",
    "y = dataset.iloc[:, 4].values\n",
    "\n",
    "# Encoding categorical data\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "labelencoder = LabelEncoder()\n",
    "X[:, 3] = labelencoder.fit_transform(X[:, 3])\n",
    "onehotencoder = OneHotEncoder(categorical_features = [3])\n",
    "X = onehotencoder.fit_transform(X).toarray()\n",
    "\n",
    "# Avoiding the Dummy Variable Trap\n",
    "X = X[:, 1:]\n",
    "\n",
    "# Splitting the dataset into the Training set and Test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 447)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "numpy: NumPy is a general-purpose array-processing package. It provides a high-performance multidimensional array object, and tools for working with these arrays. </br>\n",
    "\n",
    "matplotlib: Matplotlib is a plotting library for the Python programming language and its numerical mathematics extension NumPy. It provides an object-oriented API for embedding plots into applications using general-purpose GUI toolkits like Tkinter, wxPython, Qt, or GTK+. </br>\n",
    "\n",
    "pyplot: matplotlib. pyplot is a collection of command style functions that make matplotlib work like MATLAB.\n",
    "\n",
    "pd.read_csv: It retrieves data from csv file\n",
    "\n",
    "OneHotencoder:Encode categorical features as a one-hot numeric array.(binary variables) \n",
    "categorical_features = [0]: it holds the categories expected in the first column onehotencoder.fit_transform(X).toarray()= It retreaves the encoded array and transform the catagory with the encoded array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[     0.        1.   165349.2  136897.8  471784.1 ]\n",
      " [     0.        0.   162597.7  151377.59 443898.53]\n",
      " [     1.        0.   153441.51 101145.55 407934.54]\n",
      " [     0.        1.   144372.41 118671.85 383199.62]\n",
      " [     1.        0.   142107.34  91391.77 366168.42]\n",
      " [     0.        1.   131876.9   99814.71 362861.36]\n",
      " [     0.        0.   134615.46 147198.87 127716.82]\n",
      " [     1.        0.   130298.13 145530.06 323876.68]\n",
      " [     0.        1.   120542.52 148718.95 311613.29]\n",
      " [     0.        0.   123334.88 108679.17 304981.62]\n",
      " [     1.        0.   101913.08 110594.11 229160.95]\n",
      " [     0.        0.   100671.96  91790.61 249744.55]\n",
      " [     1.        0.    93863.75 127320.38 249839.44]\n",
      " [     0.        0.    91992.39 135495.07 252664.93]\n",
      " [     1.        0.   119943.24 156547.42 256512.92]\n",
      " [     0.        1.   114523.61 122616.84 261776.23]\n",
      " [     0.        0.    78013.11 121597.55 264346.06]\n",
      " [     0.        1.    94657.16 145077.58 282574.31]\n",
      " [     1.        0.    91749.16 114175.79 294919.57]\n",
      " [     0.        1.    86419.7  153514.11      0.  ]\n",
      " [     0.        0.    76253.86 113867.3  298664.47]\n",
      " [     0.        1.    78389.47 153773.43 299737.29]\n",
      " [     1.        0.    73994.56 122782.75 303319.26]\n",
      " [     1.        0.    67532.53 105751.03 304768.73]\n",
      " [     0.        1.    77044.01  99281.34 140574.81]\n",
      " [     0.        0.    64664.71 139553.16 137962.62]\n",
      " [     1.        0.    75328.87 144135.98 134050.07]\n",
      " [     0.        1.    72107.6  127864.55 353183.81]\n",
      " [     1.        0.    66051.52 182645.56 118148.2 ]\n",
      " [     0.        1.    65605.48 153032.06 107138.38]\n",
      " [     1.        0.    61994.48 115641.28  91131.24]\n",
      " [     0.        1.    61136.38 152701.92  88218.23]\n",
      " [     0.        0.    63408.86 129219.61  46085.25]\n",
      " [     1.        0.    55493.95 103057.49 214634.81]\n",
      " [     0.        0.    46426.07 157693.92 210797.67]\n",
      " [     0.        1.    46014.02  85047.44 205517.64]\n",
      " [     1.        0.    28663.76 127056.21 201126.82]\n",
      " [     0.        0.    44069.95  51283.14 197029.42]\n",
      " [     0.        1.    20229.59  65947.93 185265.1 ]\n",
      " [     0.        0.    38558.51  82982.09 174999.3 ]\n",
      " [     0.        0.    28754.33 118546.05 172795.67]\n",
      " [     1.        0.    27892.92  84710.77 164470.71]\n",
      " [     0.        0.    23640.93  96189.63 148001.11]\n",
      " [     0.        1.    15505.73 127382.3   35534.17]\n",
      " [     0.        0.    22177.74 154806.14  28334.72]\n",
      " [     0.        1.     1000.23 124153.04   1903.93]\n",
      " [     1.        0.     1315.46 115816.21 297114.46]\n",
      " [     0.        0.        0.   135426.92      0.  ]\n",
      " [     0.        1.      542.05  51743.15      0.  ]\n",
      " [     0.        0.        0.   116983.8   45173.06]]\n"
     ]
    }
   ],
   "source": [
    "np.set_printoptions(suppress = True)\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " np.set_printoptions(suppress = True): suppresses the use of scientific notation for small numbers to 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting Multiple Linear Regression to the Training set\n",
    "from sklearn.linear_model import LinearRegression\n",
    "regressor = LinearRegression()\n",
    "regressor.fit(X_train, y_train)\n",
    "\n",
    "# Predicting the Test set results\n",
    "y_pred = regressor.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LinearRegression fits a linear model with coefficients w = (w1, â€¦, wp) to minimize the residual sum of squares between the observed targets in the dataset, and the targets predicted by the linear approximation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([103015.20159796, 132582.27760815, 132447.73845175,  71976.09851258,\n",
       "       178537.48221056, 116161.24230166,  67851.69209676,  98791.73374687,\n",
       "       113969.43533013, 167921.06569551])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([103282.38, 144259.4 , 146121.95,  77798.83, 191050.39, 105008.31,\n",
       "        81229.06,  97483.56, 110352.25, 166187.94])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
